{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 PySpark:\n",
    "\n",
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But first, let's do some SQL :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, install and import PySPark and SparkSession**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, download the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: gdown: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=1PB6wBDVTM_eocxOyi0lWlLBQOlH0rLe_ -O PatientInfo.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a SparkSession object and name the app \"Lab2\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Lab2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Read the file PatientInfo.csv into a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"PatientInfo.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show the first 5 lines of the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre {white-space : pre !important ;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre {white-space : pre !important ;}</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|patient_id|   sex|age|country|province|       city|      infection_case|infected_by|contact_number|symptom_onset_date|confirmed_date|released_date|deceased_date|   state|\n",
      "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|1000000001|  male|50s|  Korea|   Seoul| Gangseo-gu|     overseas inflow|       null|            75|        2020-01-22|    2020-01-23|   2020-02-05|         null|released|\n",
      "|1000000002|  male|30s|  Korea|   Seoul|Jungnang-gu|     overseas inflow|       null|            31|              null|    2020-01-30|   2020-03-02|         null|released|\n",
      "|1000000003|  male|50s|  Korea|   Seoul|  Jongno-gu|contact with patient| 2002000001|            17|              null|    2020-01-30|   2020-02-19|         null|released|\n",
      "|1000000004|  male|20s|  Korea|   Seoul|    Mapo-gu|     overseas inflow|       null|             9|        2020-01-26|    2020-01-30|   2020-02-15|         null|released|\n",
      "|1000000005|female|20s|  Korea|   Seoul|Seongbuk-gu|contact with patient| 1000000002|             2|              null|    2020-01-31|   2020-02-24|         null|released|\n",
      "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now do the same but using SQL select statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a temporary view (table) called patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"patient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use SELECT statement to select all columns from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|patient_id|   sex|age|country|province|        city|      infection_case|infected_by|contact_number|symptom_onset_date|confirmed_date|released_date|deceased_date|   state|\n",
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|1000000001|  male|50s|  Korea|   Seoul|  Gangseo-gu|     overseas inflow|       null|            75|        2020-01-22|    2020-01-23|   2020-02-05|         null|released|\n",
      "|1000000002|  male|30s|  Korea|   Seoul| Jungnang-gu|     overseas inflow|       null|            31|              null|    2020-01-30|   2020-03-02|         null|released|\n",
      "|1000000003|  male|50s|  Korea|   Seoul|   Jongno-gu|contact with patient| 2002000001|            17|              null|    2020-01-30|   2020-02-19|         null|released|\n",
      "|1000000004|  male|20s|  Korea|   Seoul|     Mapo-gu|     overseas inflow|       null|             9|        2020-01-26|    2020-01-30|   2020-02-15|         null|released|\n",
      "|1000000005|female|20s|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000002|             2|              null|    2020-01-31|   2020-02-24|         null|released|\n",
      "|1000000006|female|50s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|            43|              null|    2020-01-31|   2020-02-19|         null|released|\n",
      "|1000000007|  male|20s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|             0|              null|    2020-01-31|   2020-02-10|         null|released|\n",
      "|1000000008|  male|20s|  Korea|   Seoul|         etc|     overseas inflow|       null|             0|              null|    2020-02-02|   2020-02-24|         null|released|\n",
      "|1000000009|  male|30s|  Korea|   Seoul|   Songpa-gu|     overseas inflow|       null|            68|              null|    2020-02-05|   2020-02-21|         null|released|\n",
      "|1000000010|female|60s|  Korea|   Seoul| Seongbuk-gu|contact with patient| 1000000003|             6|              null|    2020-02-05|   2020-02-29|         null|released|\n",
      "|1000000011|female|50s|  China|   Seoul|Seodaemun-gu|     overseas inflow|       null|            23|              null|    2020-02-06|   2020-02-29|         null|released|\n",
      "|1000000012|  male|20s|  Korea|   Seoul|         etc|     overseas inflow|       null|             0|              null|    2020-02-07|   2020-02-27|         null|released|\n",
      "|1000000013|  male|80s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|           117|              null|    2020-02-16|         null|         null|deceased|\n",
      "|1000000014|female|60s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000013|            27|        2020-02-06|    2020-02-16|   2020-03-12|         null|released|\n",
      "|1000000015|  male|70s|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT|       null|             8|        2020-02-11|    2020-02-19|         null|         null|released|\n",
      "|1000000016|  male|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000017|          null|              null|    2020-02-19|   2020-03-11|         null|released|\n",
      "|1000000017|  male|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000003|          null|              null|    2020-02-20|   2020-03-01|         null|released|\n",
      "|1000000018|  male|20s|  Korea|   Seoul|         etc|                 etc|       null|          null|              null|    2020-02-20|         null|         null|released|\n",
      "|1000000019|female|70s|  Korea|   Seoul|   Jongno-gu|contact with patient| 1000000021|          null|              null|    2020-02-20|   2020-03-08|         null|released|\n",
      "|1000000020|female|70s|  Korea|   Seoul|Seongdong-gu|    Seongdong-gu APT| 1000000015|          null|              null|    2020-02-20|         null|         null|released|\n",
      "+----------+------+---+-------+--------+------------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" Select * from patient\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Limit the output to only 5 rows *using SQL commands*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|patient_id|   sex|age|country|province|       city|      infection_case|infected_by|contact_number|symptom_onset_date|confirmed_date|released_date|deceased_date|   state|\n",
      "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "|1000000001|  male|50s|  Korea|   Seoul| Gangseo-gu|     overseas inflow|       null|            75|        2020-01-22|    2020-01-23|   2020-02-05|         null|released|\n",
      "|1000000002|  male|30s|  Korea|   Seoul|Jungnang-gu|     overseas inflow|       null|            31|              null|    2020-01-30|   2020-03-02|         null|released|\n",
      "|1000000003|  male|50s|  Korea|   Seoul|  Jongno-gu|contact with patient| 2002000001|            17|              null|    2020-01-30|   2020-02-19|         null|released|\n",
      "|1000000004|  male|20s|  Korea|   Seoul|    Mapo-gu|     overseas inflow|       null|             9|        2020-01-26|    2020-01-30|   2020-02-15|         null|released|\n",
      "|1000000005|female|20s|  Korea|   Seoul|Seongbuk-gu|contact with patient| 1000000002|             2|              null|    2020-01-31|   2020-02-24|         null|released|\n",
      "+----------+------+---+-------+--------+-----------+--------------------+-----------+--------------+------------------+--------------+-------------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" Select * from patient limit 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Select the count of males and females in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|   sex|count(sex)|\n",
      "+------+----------+\n",
      "|  null|         0|\n",
      "|female|      2218|\n",
      "|  male|      1825|\n",
      "+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" Select sex,count(sex) \n",
    "              from patient\n",
    "              group by sex\n",
    "              \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(sex)|\n",
      "+----------+\n",
      "|      4043|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" Select count(sex) \n",
    "              from patient\n",
    "              \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Select the count of males and females *as percentage* (how many percent of the data are males and how many are females?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|   sex|percent_of_the_data|\n",
      "+------+-------------------+\n",
      "|  null|                0.0|\n",
      "|female|  54.86025228790502|\n",
      "|  male|  45.13974771209498|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" Select sex,(count(sex)/4043 * 100) as percent_of_the_data\n",
    "              from patient\n",
    "              group by sex\n",
    "              \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. How many people did survive, and how many didn't?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|   state|count(state)|\n",
      "+--------+------------+\n",
      "|isolated|        2158|\n",
      "|released|        2929|\n",
      "|deceased|          78|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" Select state , count(state)\n",
    "              from patient\n",
    "              group by state\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform some preprocessing using SQL:\n",
    "\n",
    "1. Convert *age* column to double after removing the 's' at the end -- *hint: check SUBSTRING method*\n",
    "2. Select only the following columns: `['sex', 'age', 'province', 'state']`\n",
    "3. Store the result of the query in a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\" Select sex, CAST(Substring(age,1,2) as DECIMAL(10,2)) age, province, state\n",
    "              from patient\n",
    "\n",
    "\"\"\").write.csv(\"myresult.csv\",header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now view the new dataframe to make sure everything is alright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------+--------+\n",
      "|   sex| age|province|   state|\n",
      "+------+----+--------+--------+\n",
      "|  male|50.0|   Seoul|released|\n",
      "|  male|30.0|   Seoul|released|\n",
      "|  male|50.0|   Seoul|released|\n",
      "|  male|20.0|   Seoul|released|\n",
      "|female|20.0|   Seoul|released|\n",
      "|female|50.0|   Seoul|released|\n",
      "|  male|20.0|   Seoul|released|\n",
      "|  male|20.0|   Seoul|released|\n",
      "|  male|30.0|   Seoul|released|\n",
      "|female|60.0|   Seoul|released|\n",
      "|female|50.0|   Seoul|released|\n",
      "|  male|20.0|   Seoul|released|\n",
      "|  male|80.0|   Seoul|deceased|\n",
      "|female|60.0|   Seoul|released|\n",
      "|  male|70.0|   Seoul|released|\n",
      "|  male|70.0|   Seoul|released|\n",
      "|  male|70.0|   Seoul|released|\n",
      "|  male|20.0|   Seoul|released|\n",
      "|female|70.0|   Seoul|released|\n",
      "|female|70.0|   Seoul|released|\n",
      "+------+----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = spark.read.csv(\"myresult.csv\",header=True,inferSchema=True)\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's get back to spark operations**\n",
    "\n",
    "Please copy the following operations from your solution in Lab 1\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a **is_dead** column if patient state is not released then it should yield true, else then False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------+--------+-------+\n",
      "|   sex| age|province|   state|is_dead|\n",
      "+------+----+--------+--------+-------+\n",
      "|  male|50.0|   Seoul|released|      1|\n",
      "|  male|30.0|   Seoul|released|      1|\n",
      "|  male|50.0|   Seoul|released|      1|\n",
      "|  male|20.0|   Seoul|released|      1|\n",
      "|female|20.0|   Seoul|released|      1|\n",
      "|female|50.0|   Seoul|released|      1|\n",
      "|  male|20.0|   Seoul|released|      1|\n",
      "|  male|20.0|   Seoul|released|      1|\n",
      "|  male|30.0|   Seoul|released|      1|\n",
      "|female|60.0|   Seoul|released|      1|\n",
      "|female|50.0|   Seoul|released|      1|\n",
      "|  male|20.0|   Seoul|released|      1|\n",
      "|  male|80.0|   Seoul|deceased|      0|\n",
      "|female|60.0|   Seoul|released|      1|\n",
      "|  male|70.0|   Seoul|released|      1|\n",
      "|  male|70.0|   Seoul|released|      1|\n",
      "|  male|70.0|   Seoul|released|      1|\n",
      "|  male|20.0|   Seoul|released|      1|\n",
      "|female|70.0|   Seoul|released|      1|\n",
      "|female|70.0|   Seoul|released|      1|\n",
      "+------+----+--------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "df_new = df_new.withColumn(\"is_dead\",when(col(\"state\")==\"released\",1).otherwise(0))\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please split the data into train and test dataframes**\n",
    "\n",
    "*Ratio: 80:20 - Seed=42*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf, testDf = df_new.randomSplit([.8,.2],seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----------+--------+-------+\n",
      "| sex| age|   province|   state|is_dead|\n",
      "+----+----+-----------+--------+-------+\n",
      "|null|null|Gyeonggi-do|isolated|      0|\n",
      "|null|null|Gyeonggi-do|isolated|      0|\n",
      "|null|null|Gyeonggi-do|isolated|      0|\n",
      "|null|null|Gyeonggi-do|isolated|      0|\n",
      "|null|null|Gyeonggi-do|isolated|      0|\n",
      "+----+----+-----------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's import RandomForestClassifier and start our ML pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a pipeline that contains the following stages:**\n",
    "\n",
    "- Imputer: impute the null values in `age` column to the mean value\n",
    "- StringIndexer: convert `sex` to `is_male` and `province` to `province_index` as numerical values\n",
    "- OneHotEncoder: perform one hot encoding on both `is_male` and -province_index`\n",
    "- VectorAssembler: assemble feature vector from the following columns: `'age', 'is_male', 'province_index'`\n",
    "- RandomForestClassifier: final estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "imputer = Imputer(inputCol=\"age\",outputCol=\"age\")\n",
    "\n",
    "index = StringIndexer(inputCols=[\"sex\",\"province\"], outputCols=[\"is_male\",\"province_index\"],handleInvalid=\"skip\")\n",
    "ohe = OneHotEncoder(inputCols=[\"is_male\",\"province_index\"], outputCols=[\"is_male_\",\"province_index_\"])\n",
    "assembler = VectorAssembler(\n",
    "                            inputCols=[\"age\",\"is_male_\",\"province_index_\"],\n",
    "                            outputCol=\"features\")\n",
    "rfc = RandomForestClassifier(featuresCol=\"features\",labelCol=\"is_dead\",predictionCol=\"prediction\")\n",
    "model = Pipeline(stages=[imputer,index,ohe,assembler,rfc]).fit(trainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the pipeline to the train dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transform the test DF to get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.transform(testDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the final predictions DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-----------------+--------+-------+-------+--------------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|   sex|              age|         province|   state|is_dead|is_male|province_index|     is_male_|province_index_|            features|       rawPrediction|         probability|prediction|\n",
      "+------+-----------------+-----------------+--------+-------+-------+--------------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|female|40.83025210084033|Chungcheongnam-do|released|      1|    0.0|           4.0|(1,[0],[1.0])| (16,[4],[1.0])|(18,[0,1,6],[40.8...|[8.13297885295184...|[0.40664894264759...|       1.0|\n",
      "|female|40.83025210084033|Chungcheongnam-do|released|      1|    0.0|           4.0|(1,[0],[1.0])| (16,[4],[1.0])|(18,[0,1,6],[40.8...|[8.13297885295184...|[0.40664894264759...|       1.0|\n",
      "|female|40.83025210084033|            Daegu|isolated|      0|    0.0|           6.0|(1,[0],[1.0])| (16,[6],[1.0])|(18,[0,1,8],[40.8...|[15.0135678421679...|[0.75067839210839...|       0.0|\n",
      "|female|40.83025210084033|      Gyeonggi-do|isolated|      0|    0.0|           2.0|(1,[0],[1.0])| (16,[2],[1.0])|(18,[0,1,4],[40.8...|[16.1005634853724...|[0.80502817426862...|       0.0|\n",
      "|female|40.83025210084033| Gyeongsangbuk-do|isolated|      0|    0.0|           1.0|(1,[0],[1.0])| (16,[1],[1.0])|(18,[0,1,3],[40.8...|[3.45256728339850...|[0.17262836416992...|       1.0|\n",
      "|female|40.83025210084033| Gyeongsangbuk-do|released|      1|    0.0|           1.0|(1,[0],[1.0])| (16,[1],[1.0])|(18,[0,1,3],[40.8...|[3.45256728339850...|[0.17262836416992...|       1.0|\n",
      "|female|40.83025210084033| Gyeongsangbuk-do|released|      1|    0.0|           1.0|(1,[0],[1.0])| (16,[1],[1.0])|(18,[0,1,3],[40.8...|[3.45256728339850...|[0.17262836416992...|       1.0|\n",
      "|female|40.83025210084033| Gyeongsangbuk-do|released|      1|    0.0|           1.0|(1,[0],[1.0])| (16,[1],[1.0])|(18,[0,1,3],[40.8...|[3.45256728339850...|[0.17262836416992...|       1.0|\n",
      "|female|40.83025210084033| Gyeongsangbuk-do|released|      1|    0.0|           1.0|(1,[0],[1.0])| (16,[1],[1.0])|(18,[0,1,3],[40.8...|[3.45256728339850...|[0.17262836416992...|       1.0|\n",
      "|female|40.83025210084033| Gyeongsangbuk-do|released|      1|    0.0|           1.0|(1,[0],[1.0])| (16,[1],[1.0])|(18,[0,1,3],[40.8...|[3.45256728339850...|[0.17262836416992...|       1.0|\n",
      "|female|40.83025210084033|          Incheon|isolated|      0|    0.0|           3.0|(1,[0],[1.0])| (16,[3],[1.0])|(18,[0,1,5],[40.8...|[13.4968148280584...|[0.67484074140292...|       0.0|\n",
      "|female|40.83025210084033|          Incheon|isolated|      0|    0.0|           3.0|(1,[0],[1.0])| (16,[3],[1.0])|(18,[0,1,5],[40.8...|[13.4968148280584...|[0.67484074140292...|       0.0|\n",
      "|female|40.83025210084033|          Incheon|isolated|      0|    0.0|           3.0|(1,[0],[1.0])| (16,[3],[1.0])|(18,[0,1,5],[40.8...|[13.4968148280584...|[0.67484074140292...|       0.0|\n",
      "|female|40.83025210084033|          Incheon|isolated|      0|    0.0|           3.0|(1,[0],[1.0])| (16,[3],[1.0])|(18,[0,1,5],[40.8...|[13.4968148280584...|[0.67484074140292...|       0.0|\n",
      "|female|40.83025210084033|          Incheon|isolated|      0|    0.0|           3.0|(1,[0],[1.0])| (16,[3],[1.0])|(18,[0,1,5],[40.8...|[13.4968148280584...|[0.67484074140292...|       0.0|\n",
      "|female|40.83025210084033|          Incheon|isolated|      0|    0.0|           3.0|(1,[0],[1.0])| (16,[3],[1.0])|(18,[0,1,5],[40.8...|[13.4968148280584...|[0.67484074140292...|       0.0|\n",
      "|female|40.83025210084033|          Incheon|isolated|      0|    0.0|           3.0|(1,[0],[1.0])| (16,[3],[1.0])|(18,[0,1,5],[40.8...|[13.4968148280584...|[0.67484074140292...|       0.0|\n",
      "|female|40.83025210084033|          Incheon|isolated|      0|    0.0|           3.0|(1,[0],[1.0])| (16,[3],[1.0])|(18,[0,1,5],[40.8...|[13.4968148280584...|[0.67484074140292...|       0.0|\n",
      "|female|40.83025210084033|          Incheon|isolated|      0|    0.0|           3.0|(1,[0],[1.0])| (16,[3],[1.0])|(18,[0,1,5],[40.8...|[13.4968148280584...|[0.67484074140292...|       0.0|\n",
      "|female|40.83025210084033|          Incheon|isolated|      0|    0.0|           3.0|(1,[0],[1.0])| (16,[3],[1.0])|(18,[0,1,5],[40.8...|[13.4968148280584...|[0.67484074140292...|       0.0|\n",
      "+------+-----------------+-----------------+--------+-------+-------+--------------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+-------+----------+\n",
      "|features                                |is_dead|prediction|\n",
      "+----------------------------------------+-------+----------+\n",
      "|(18,[0,1,6],[40.83025210084033,1.0,1.0])|1      |1.0       |\n",
      "|(18,[0,1,6],[40.83025210084033,1.0,1.0])|1      |1.0       |\n",
      "|(18,[0,1,8],[40.83025210084033,1.0,1.0])|0      |0.0       |\n",
      "|(18,[0,1,4],[40.83025210084033,1.0,1.0])|0      |0.0       |\n",
      "|(18,[0,1,3],[40.83025210084033,1.0,1.0])|0      |1.0       |\n",
      "+----------------------------------------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.select('features','is_dead','prediction').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**\n",
    "\n",
    "Now let's evaluate our model! Let's get the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "ev = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",labelCol=\"is_dead\",metricName=\"areaUnderPR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873873074990393"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.evaluate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandsDf = pred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>state</th>\n",
       "      <th>is_dead</th>\n",
       "      <th>is_male</th>\n",
       "      <th>province_index</th>\n",
       "      <th>is_male_</th>\n",
       "      <th>province_index_</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>40.830252</td>\n",
       "      <td>Chungcheongnam-do</td>\n",
       "      <td>released</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(40.83025210084033, 1.0, 0.0, 0.0, 0.0, 0.0, 1...</td>\n",
       "      <td>[8.132978852951844, 11.867021147048156]</td>\n",
       "      <td>[0.4066489426475922, 0.5933510573524078]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>40.830252</td>\n",
       "      <td>Chungcheongnam-do</td>\n",
       "      <td>released</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(40.83025210084033, 1.0, 0.0, 0.0, 0.0, 0.0, 1...</td>\n",
       "      <td>[8.132978852951844, 11.867021147048156]</td>\n",
       "      <td>[0.4066489426475922, 0.5933510573524078]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>40.830252</td>\n",
       "      <td>Daegu</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>(40.83025210084033, 1.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[15.013567842167967, 4.986432157832032]</td>\n",
       "      <td>[0.7506783921083984, 0.24932160789160157]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>40.830252</td>\n",
       "      <td>Gyeonggi-do</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(40.83025210084033, 1.0, 0.0, 0.0, 1.0, 0.0, 0...</td>\n",
       "      <td>[16.100563485372422, 3.89943651462758]</td>\n",
       "      <td>[0.8050281742686209, 0.19497182573137894]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>40.830252</td>\n",
       "      <td>Gyeongsangbuk-do</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(40.83025210084033, 1.0, 0.0, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[3.4525672833985075, 16.54743271660149]</td>\n",
       "      <td>[0.17262836416992539, 0.8273716358300746]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>male</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>Gyeonggi-do</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(90.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[16.16880135876239, 3.8311986412376102]</td>\n",
       "      <td>[0.8084400679381195, 0.19155993206188052]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>male</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>Gyeongsangbuk-do</td>\n",
       "      <td>deceased</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(90.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[3.60874068373907, 16.391259316260932]</td>\n",
       "      <td>[0.1804370341869535, 0.8195629658130466]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>male</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>Gyeongsangbuk-do</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(90.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[3.60874068373907, 16.391259316260932]</td>\n",
       "      <td>[0.1804370341869535, 0.8195629658130466]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>male</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>Gyeongsangbuk-do</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(90.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[3.60874068373907, 16.391259316260932]</td>\n",
       "      <td>[0.1804370341869535, 0.8195629658130466]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>male</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>Gyeongsangbuk-do</td>\n",
       "      <td>isolated</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(90.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[3.60874068373907, 16.391259316260932]</td>\n",
       "      <td>[0.1804370341869535, 0.8195629658130466]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex        age           province     state  is_dead  is_male  \\\n",
       "0    female  40.830252  Chungcheongnam-do  released        1      0.0   \n",
       "1    female  40.830252  Chungcheongnam-do  released        1      0.0   \n",
       "2    female  40.830252              Daegu  isolated        0      0.0   \n",
       "3    female  40.830252        Gyeonggi-do  isolated        0      0.0   \n",
       "4    female  40.830252   Gyeongsangbuk-do  isolated        0      0.0   \n",
       "..      ...        ...                ...       ...      ...      ...   \n",
       "805    male  90.000000        Gyeonggi-do  isolated        0      1.0   \n",
       "806    male  90.000000   Gyeongsangbuk-do  deceased        0      1.0   \n",
       "807    male  90.000000   Gyeongsangbuk-do  isolated        0      1.0   \n",
       "808    male  90.000000   Gyeongsangbuk-do  isolated        0      1.0   \n",
       "809    male  90.000000   Gyeongsangbuk-do  isolated        0      1.0   \n",
       "\n",
       "     province_index is_male_  \\\n",
       "0               4.0    (1.0)   \n",
       "1               4.0    (1.0)   \n",
       "2               6.0    (1.0)   \n",
       "3               2.0    (1.0)   \n",
       "4               1.0    (1.0)   \n",
       "..              ...      ...   \n",
       "805             2.0    (0.0)   \n",
       "806             1.0    (0.0)   \n",
       "807             1.0    (0.0)   \n",
       "808             1.0    (0.0)   \n",
       "809             1.0    (0.0)   \n",
       "\n",
       "                                       province_index_  \\\n",
       "0    (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1    (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2    (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "3    (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4    (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "..                                                 ...   \n",
       "805  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "806  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "807  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "808  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "809  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              features  \\\n",
       "0    (40.83025210084033, 1.0, 0.0, 0.0, 0.0, 0.0, 1...   \n",
       "1    (40.83025210084033, 1.0, 0.0, 0.0, 0.0, 0.0, 1...   \n",
       "2    (40.83025210084033, 1.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "3    (40.83025210084033, 1.0, 0.0, 0.0, 1.0, 0.0, 0...   \n",
       "4    (40.83025210084033, 1.0, 0.0, 1.0, 0.0, 0.0, 0...   \n",
       "..                                                 ...   \n",
       "805  (90.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "806  (90.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "807  (90.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "808  (90.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "809  (90.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                               rawPrediction  \\\n",
       "0    [8.132978852951844, 11.867021147048156]   \n",
       "1    [8.132978852951844, 11.867021147048156]   \n",
       "2    [15.013567842167967, 4.986432157832032]   \n",
       "3     [16.100563485372422, 3.89943651462758]   \n",
       "4    [3.4525672833985075, 16.54743271660149]   \n",
       "..                                       ...   \n",
       "805  [16.16880135876239, 3.8311986412376102]   \n",
       "806   [3.60874068373907, 16.391259316260932]   \n",
       "807   [3.60874068373907, 16.391259316260932]   \n",
       "808   [3.60874068373907, 16.391259316260932]   \n",
       "809   [3.60874068373907, 16.391259316260932]   \n",
       "\n",
       "                                   probability  prediction  \n",
       "0     [0.4066489426475922, 0.5933510573524078]         1.0  \n",
       "1     [0.4066489426475922, 0.5933510573524078]         1.0  \n",
       "2    [0.7506783921083984, 0.24932160789160157]         0.0  \n",
       "3    [0.8050281742686209, 0.19497182573137894]         0.0  \n",
       "4    [0.17262836416992539, 0.8273716358300746]         1.0  \n",
       "..                                         ...         ...  \n",
       "805  [0.8084400679381195, 0.19155993206188052]         0.0  \n",
       "806   [0.1804370341869535, 0.8195629658130466]         1.0  \n",
       "807   [0.1804370341869535, 0.8195629658130466]         1.0  \n",
       "808   [0.1804370341869535, 0.8195629658130466]         1.0  \n",
       "809   [0.1804370341869535, 0.8195629658130466]         1.0  \n",
       "\n",
       "[810 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Now let's generate the confusion matrix of our predictions\n",
    "\n",
    "*Hint: we can use `scikit-learn`'s `classification_report`. You will need to transform the predictions into pandas DF first*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86       306\n",
      "           1       0.89      0.95      0.92       504\n",
      "\n",
      "    accuracy                           0.90       810\n",
      "   macro avg       0.90      0.88      0.89       810\n",
      "weighted avg       0.90      0.90      0.90       810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(pandsDf['is_dead'], pandsDf['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd1a844898bebfcc6c6c504d1dc786ee6fa9d0c6b1f1b5f42f0cc60440be92ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
